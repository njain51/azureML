
# Training model on Remote Compute:

#### Following Steps to be done: 

- Creating Experiment
- Integrating Script for model Training that will execute on cluster
- implementing an Estimator
- Configuring Training Environment
- running an Experiment
- Registering our model for reuse in the workspace


### creating experiment 



- we will work with this file in Notebook: [here](exercise_files/04/demos/demos/2_Training a Model on Remote Compute.ipynb)


### Training Model 
```text
Training a Model
[Autogenerated] And so now that we've talked about how we leverage compute resource is we're going to transition into actually building and training a model. So over the course of this demo, we're first going to be creating our first experiment within the platform. Then we'll be implementing a script for model training that will execute on a compute cluster. So a remote compute cluster. Then we'll be implementing an estimator because, as mentioned, we're leveraging care is on top of tensorflow. Then we'll be configuring the training environment, running our experiment and then registering our model for re use within the workspace. So I'm here in my Jupyter notebook and as you've noticed, we have a data directory and we included this through the first notebook that we ran. And this is what downloaded the emyn is data into our notebook. But we're going to now click on number two, training a model on remote compute. And here within this notebook, the first thing we need to do is we need to do some imports. And just as we did before, we're gonna make sure that we're working with the correct version of the Azure machine learning sdk. Now that we've imported the needed modules. We're now going to create our first experiment. And to do this we'll first need to get a reference back to our workspace. Just as. We did before. And then we'll create a new experiment named caret SSHD. Azure reminisced, and here we can see it has returned the needed information about both our workspace and our experiment. Now, the next thing we need to do is we need to create a directory that is going to house all of the scripts that will be needed to train our model. And these are the scripts that we will then be sending up to remote compute to actually execute. So we'll make sure that this directory has been created. And now the next thing we need to do is actually create this script. So let's walk through what we have here. First of all, you can see that we are using right file. So we are gonna export this and we're gonna export this into a file called train pay. And so, in this case, we're bringing in some normal things that we would bring in, including art parts, because we're gonna be pulling in arguments and It's also important to note here that we're gonna be pulling in the run class from Azure ml core. And this is what gives us the context of the current run. And we'll see later how we actually use that within this file. And then, in addition, we're also pulling out information about care is and then we want to be sure that we're bringing in tensorflow. So we can log out the tensorflow versioning. Now the first thing we need to do here is we're going to look a argument handling because we are able to pass in arguments into the remote compute instance. And this is important because we can choose to go through and adjust those parameters. So, for example, one of the arguments were passing. Here is the number of epochs. And if we wanna have it test out four different versions and let us know which has the best accuracy rate, we can configure that here, Although that's beyond the scope of what we're gonna be covering within this course. So first we're handling those arguments, then we're actually gonna load in our data. And this is very much the same way that we loaded in data within the first notebook with just a few adjustments that we need to get the data in the right format for care is, then we're going to get that context. That context is going to give us reference to this run variable that we can then use to pass in our metrics once our model has been trained and compiled. So next we're actually gonna create the model. And in this case, we're just using care is we're using a sequential model and we're using a very simplified version. We're going to have one initial layer to flatten everything, and then we're gonna have a dense layer, and then we're going to have a soft max layer at the end. And with this, we're then going to compile the model and you'll notice here that we are specifying that we want to get the accuracy back because that is going to be the metric that we want to send back to the service. And that's why we got a reference to the run context, because that's what we're going to use to pass in that accuracy value. Then we'll actually fit our model and ultimately evaluated. And then you can see where we're actually logging that accuracy score. Now you can include as many different metrics as you want from your model here for simplicity. We're choosing to just include one, and in the last bit here. That's very critical is we're also saving our model. So we're going to look to create a directory outputs slash model and then in there we're going to say about our model as an H five file. Now. The next thing we need to do is we need to actually copy over that you tills dot Python file that we had previously that has a utility in it for loading the data because we'll need to have access to that also on our remote compute. So now I'm going to go ahead and run both of these cells, and it lets us know that its output those files accordingly. Now the next thing we're going to do is we're going to be working with an estimator, and we're going to be working with an estimator that is specifically for tensor flow. And since we're working with keras is on top of tensorflow, this should meet our needs now generally, when working with an estimator. We need to look at our environment configuration script parameters are script directory, an entry point and ultimately, our compute cluster and its configuration. So the first thing we're gonna look at here is script parameters, and we're going to actually look at our environment creation when we actually get to creating our estimator itself. So here first, we're gonna go ahead and run this So we specify our script parameters. Now we're going to be including a reference to the emyn is dataset We're gonna mount that in as a directory, since that is a publicly available dataset as opposed to having to pass all of that data over to every remote compute cluster. Now, the next thing we're gonna do is we're actually going to get a reference to our compute cluster, and then we're going to create our estimator and here within the estimator, we're gonna pass in first the script folder. So, in essence, the folder where we dumped those files that we knew we would need. We're then going to give it the entry script name. So the file that needs to be run to actually train compiling evaluator model, we then pass in our script, Paramus, our reference to our cluster and then we need to give it a framework version. And in this case, we're using tensorflow too. Then we need to customize our environment with the last two variables that are passed in. First we need to pass in the argument that lets it know what pit packages need to be installed. And in this case, we're gonna be using the Azure ML data prep with fuse and pandas. And then we're also going to be leveraging care is as mentioned, so we need to be sure that those are installed. And finally we pass in one additional option, which is that we wanted to use the GPU because we are using a GPU based compute cluster now that we have all of that configured we can actually run this cell. But before we do, I want to mention that if we weren't using an estimator, there would be a lot of additional steps we would need to actually take, including creating an environment file and several other things that we would need to do that because we're using a standard framework and we're using an estimator. It does eliminate some of those steps. So now we'll hit. Run! Now, once we've done that, we can actually submit our first run. Now, this is going to take a while to execute. It's going to need to spin up. The compute resource is to actually do the work, but we'll go ahead and start this. And one of the benefits here is that within the sdk they've included away to monitor your runs from within your Jupyter notebook. So here, I'm going to go ahead and use this run details option, and it will pull up here real time logs as well as the current status of our run here just within our notebook. But we also have the opportunity here to click and see this within machine learning studio. So I'm going to open up this tab we can go in here and we can see that it's going to take us to our run, and it lets us know here first that are run is cute, which means that we're waiting for it to get the compute resource is to actually be able to execute this we can. Now go look at our compute cluster and we can See here that the allocation state currently is steady, and it has zero nodes that have been allocated. So if we were to actually stay and watch this, we would notice that this would transition in a minute to be re sizing. Because now that we've submitted are run, we're going to need compute capabilities. And now we can see, indeed it is in a re sizing state, it's gonna be re sizing from a 0 to 1. And so now we need to weight on this to finish. And so we're going to navigate back over to our notebook, and now we can see that are run has completed and we can see that our accuracy rate in this case is 97.5. We've been able to achieve that with the model that we submitted. And so now we can also see that if we actually go down and hit the run dot get metrics call. This will give us back the same metric that we had included previously and again. This is available because we got the run context and registered our metrics with that within our training script. So now we're going to register our model. We're gonna give it the name caret stash reminisced, and we're going to give a reference to the path where we save this out within our training script. Now we've registered our model, and the next step will be for us to deploy this so we can operationalize it within our organization.
```