
# Project intro

- got MNIST data from here: https://docs.microsoft.com/en-us/azure/open-datasets/dataset-mnist?tabs=azureml-opendatasets

> The Azure Machine Learning Python SDK includes the MNIST data as one of the open sata sets, which enables it to be included into our project easily.

### other datasets
- https://docs.microsoft.com/en-us/python/api/azureml-opendatasets/azureml.opendatasets?view=azure-ml-py#class

### Launching notebook server and running data set

- run this [file](exercise_files/04/demos/demos/1_Getting the Data Set.ipynb) for results
- its using utils.py and display.py for further transformation of images
- so running in Jupyter we were able to import our dataset and reshape it and check for sample data visualization.


### leveraging compute for model training
2 options: 
- Local Compute
- Remote Compute: options are remote machine, azure data bricks, azure ML compute, azure Data Lake Analytics

- we will focus on azure ML compute cluster - it provides both cpu and gpu option, it cna integrate with pipeline, enables hyperparameter tuning

- multiple ways to train models
1. Run Configuration -> most customizable
2. Automated ML
3. Estimators: for tensorflow etc. 
4. ML Pipeline 





