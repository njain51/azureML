
# Deploy Model

```text


Deploying a Model
[Autogenerated] So now that we've grabbed our data and we actually have built and we have trained our model, we're now ready to deploy our model. So over the course of this demo, we're first going to be retrieving our model from the workspace. Then we'll be validating are saved model locally before we deploy it. Then we'll create a scoring script to perform inference from our model, will deploy our model as a web service and then will validate that from both the python sdk and an HTTP request. So here I've pulled up the third notebook. The first step we need to take is we need to import some modules just as before. Once we've done that, we're now going to go through the process of actually pulling our model down and loading it back into care is so we'll first get a reference to our workspace, will then get a reference to our model, will download it, and then we'll load that back into care is using the load model function. Once we have that, we now need to load back in our data so that we can work with it. So in this next area, we're going to be downloading our data just as we've done before. And then we're going to be adding in a few new functions that allow us to visualize the predictions from our model. Now that we have that in place and we can see the correct shape for our data, we're now ready to do influence on the first five items within our training images. And here we can see within this visualization it shows us first the image on the left and then on the right. It actually shows us the prediction. And you can see here with the first one. This is a zero, and clearly the prediction says that it is a zero, and you can see here is we scroll down through all of these that we're going to see similar results. And so this allows us to confirm a couple of things. First of all, we have our data in the correct format. And then, in addition, we're able to use the model for inference and were able to pull those predictions out. So now that we validated our model locally, we're now ready to deploy it as a web service and that we need to create a file that will be deployed for our service, and we need to implement two functions within this file. First of all, we need to implement a NIT and within a knit. This is where we need to actually load in our model and by loading in our model, which in this case, is the emyn is dot h five file. We are then able to access it from within the run function, and the run function is what will actually make the prediction and then output the data. And then we have a utility function here called Construct output, which gives us the output we want in terms of the structure of data for each of the different values that are passed in. So once we have this written, we need to add in some configuration for the environment that will be running our web service. We need to let it know that there are two columns packages that need to be installed. Tensorflow and care is we'll use this to create an environment file and then here within this cell will actually output that environment file so that we can see it. So here, within our environment file, you can see that we are specifying the specific version of Python, the things that need to be installed with pip and the things that need to be installed via Kanda. And then we're specifying the channel here, which is columns forge Now. Next, we need to actually deploy our configuration and you'll notice Here we are using the Web service. So instead of using kubernetes, we're gonna be using the azure container instances for this specific web service for more complex use. Cases, especially, for instance, is that require a massive amount of ram, a ks, maybe a better choice. So we'll go ahead and create our configuration and once we have our configuration in place, will be ready to actually execute the deployment of our model. And here as we're waiting for our web service to deploy we can, navigate back to the Azure Machine Learning Studio and we can click on endpoints. You'll notice here that we have both real time and pipeline endpoints again. We'll be talking more about pipelines in an upcoming module, but we can see here that we are in the process of deploying are in point, which is the caress in is services endpoint, and if we pull it up we can See here that we are now in a healthy state, so we can now actually call our endpoint. So lets navigate back over to our notebook, and here we can see it has completed. And now we can actually use the service dot scoring you are. I call to actually get the u r l for our service. Now that we have this in place, we can now validate this two different ways. First of all, we're going to validate this by just using the python sdk. So since we have a reference to the service object we can just call service dot run and then pass in our input data. So let's go ahead and run that. And here we can see we have the data that's returned. This initial data for us is going to be the data for the image. So this is what has passed into the service. So it gets all the different values for the 28 by 28 image here. We can see here that the predicted value is a five and we can see that that is indeed correct. And the certainty here on this is 99.9%. So that's pretty high. And then you can see the raw results. Here we get back the value and the certainty and then all of the different possibilities for each of the different digits. Now, next, we're gonna test this via HTTP. So here, we're going to use the request module here within Python. And we're going to actually run this and validate that we can. Get the correct value back. Just using this HTTP request. Now we're gonna be setting a header here so that the content type that we're gonna be passing in is JSON. And then we're gonna be constructing JSON based on the value of one of the images, just like we did before. So we're gonna hit run on this and we'll see the same data that's actually returned. If we scroll down, we should actually see that we have a predicted value here of a seven and we can See, that were 82.6% certain, and then we can see all of the other values that are returned Now, In addition to testing it this way, we also could validate that our service works by using a tool like postman. So here within postman, I have included the URL that was included from the deployment of our model and here within the body. I'm specifying that we're using JSON data and that it's going to be raw data. And now I've pasted in here the value for what is going to be a number eight. So if I hit send, we should be able to scroll down and see that we did get a 200 response. It does return to us that it is an eight with 99.9% certainty and we can see all of the other possibilities that are included. So now we have validated that we have been able to deploy our model and tested via both the python sdk as well as Via and HTTP request both from a tool like postman as well as from within our Jupyter notebook.
```

