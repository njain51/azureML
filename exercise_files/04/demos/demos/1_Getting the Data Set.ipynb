{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Configuring the Data for our Model\n",
    "\n",
    "In this notebook, you will walk through the process to configure the data that you will be leveraging for your model. There are additional capabilities for centralizing and managing data that will be covered in future modules.\n",
    "\n",
    "## MNIST Data Set\n",
    "\n",
    "We will be leveraging the industry standard training data set, [MNIST](https://azure.microsoft.com/services/open-datasets/catalog/mnist/) along with Keras and TensorFlow.\n",
    "\n",
    "The MNIST database of handwritten digits is a common data set that is used when learning to solve the classification problem with neural networks. The Azure Machine Learning Python SDK includes the MNIST data as one of the open sata sets, which enables it to be included into our project easily.\n",
    "\n",
    "> \"The MNIST database of handwritten digits, available from this page, has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image.It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting.\"\n",
    "\n",
    "You can see some sample images from this data set in the image below:\n",
    "\n",
    "![](mnist_data.png)\n",
    "\n",
    "If you want to see which other data sets can be easily included in your project with the SDK, you [see the list here](https://docs.microsoft.com/en-us/python/api/azureml-opendatasets/azureml.opendatasets?view=azure-ml-py#classes).\n",
    "\n",
    "\n",
    "## Module\n",
    "\n",
    "Within this module, you will be:\n",
    "\n",
    "- Setup a notebook server in the Azure Machine Learning Studio\n",
    "- Download and Analyze MNIST Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Python Packages\n",
    "\n",
    "You will first need to import the following Python packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following packages will be needed from the Azure ML Python SDK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "from azureml.core import Dataset\n",
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.opendatasets import MNIST\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workspace\n",
    "\n",
    "If you are running this notebook as a part of your Azure Machine Learning Studio workspace, you can get a reference to your workspace by simply running the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "print(\"Azure ML Workspace\")\n",
    "print(f'Name: {ws.name}')\n",
    "print(f'Location: {ws.location}')\n",
    "print(f'Resource Group: {ws.resource_group}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provisioning Compute Resources\n",
    "\n",
    "We will include the logic from the previous module around provisioning compute resources.  This will create a cluster of Standard NC6 instances that can scale from 0 to 4 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a name for our new cluster\n",
    "cpu_cluster_name = 'tdsp-cluster'\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    cpu_cluster = AmlCompute(workspace=ws, name=cpu_cluster_name)\n",
    "    print('Cluster already exists.')\n",
    "    \n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_NC6',\n",
    "                                                           max_nodes=4)\n",
    "    cpu_cluster = AmlCompute.create(ws, cpu_cluster_name, compute_config)\n",
    "\n",
    "cpu_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `get_status()` method on the `cpu_cluster` instance to get the details on our compute cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = cpu_cluster.get_status()\n",
    "print(f'Nodes: {str(status.current_node_count)}')\n",
    "print(f'VM Size: {str(status.vm_size)}')\n",
    "print(f'Provsioning State: {str(status.provisioning_state)}')\n",
    "print(f'Scale Settings: {str(status.scale_settings.serialize())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information around GPU VM instances, view the following link:\n",
    "    \n",
    "* [GPU optimized virtual machine sizes](https://docs.microsoft.com/en-us/azure/virtual-machines/windows/sizes-gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Set\n",
    "\n",
    "We first need to setup the directory that will store our data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = os.path.join(os.getcwd(), 'data')\n",
    "print(f'Data folder: {data_folder}')\n",
    "os.makedirs(data_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will use the open dataset for MNIST that exists within the Azure ML Python SDK.  We will get a reference to the data set, and then we will download the data into the directory that we just created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_file_dataset = MNIST.get_file_dataset()\n",
    "mnist_file_dataset.download(data_folder, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Data\n",
    "\n",
    "To be able to load and visualize the data, we will be leverage methods from two files that are included with this notebook, `utils.py` and `display.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure utils.py is in the same directory as this code\n",
    "from utils import load_data\n",
    "from display import find_sample_data\n",
    "from display import plot_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to load in the train and test data (both images and labels). We will leverage the `load_data` function that is inlcuded from Microsoft in the `utils.py` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note we also shrink the intensity values (X) from 0-255 to 0-1. This helps the model converge faster.\n",
    "training_images = load_data(data_folder, \"train-images-idx3-ubyte.gz\") / 255.0\n",
    "training_images = np.reshape(training_images, (-1, 28,28))\n",
    "test_images = load_data(data_folder, \"t10k-images-idx3-ubyte.gz\") / 255.0\n",
    "test_images = np.reshape(test_images, (-1, 28,28))\n",
    "\n",
    "training_labels = load_data(data_folder, \"train-labels-idx1-ubyte.gz\", True).reshape(-1)\n",
    "test_labels = load_data(data_folder, \"t10k-labels-idx1-ubyte.gz\", True).reshape(-1)\n",
    "\n",
    "print(f'Training Image: {training_images.shape}')\n",
    "print(f'Training Labels: {training_labels.shape}')\n",
    "print(f'Test Images: {test_images.shape}')\n",
    "print(f'Test Labels: {test_labels.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can visulalize some of the data that we have pulled in.  We can review four examples of each category from the test data using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# find exmaples of the data and visualize it\n",
    "extracted_test_data = find_sample_data(training_images, training_labels, 8, randomize=False)\n",
    "plot_images(extracted_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
